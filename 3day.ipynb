{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b613bd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok, {'thin': 6392, 'normal': 5886, 'fat': 7722}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, metrics\n",
    "import glob, os.path, re, json\n",
    "# 텍스트를 읽어 들이고 출현 빈도 조사하기 --- (※1)\n",
    "def check_freq(fname):\n",
    "    name = os.path.basename(fname)  # 파일명 가져오기\n",
    "    lang = re.match(r'^[a-z]{2,}', name).group() # a부터 z까지가 2번 이상 반복 # 나라id 분류 group()\n",
    "    #  group()은 정규 표현식에 일치하는 것만 가져옴. 파일명에서 a부터 z까지가 2번 이상 나오는 문자를 가져온다.\n",
    "    with open(fname, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    text = text.lower() # 소문자 변환:파일에 있는 모든 내용을 소문자로 읽어 옴.\n",
    "\n",
    "    #숫자 세기 변수(cnt) 초기화하기\n",
    "    cnt = [0 for n in range(0, 26)] # 0으로 이루어진 26요소를 가진 리스트 cnt\n",
    "    code_a = ord(\"a\") # a에 해당하는 아스키값 가지고 오기\n",
    "    code_z = ord(\"z\") # z에 해당하는 아스키값 가지고 오기\n",
    "\n",
    "    # 알파벳 출현 횟수 구하기 --- (※2)\n",
    "    for ch in text:\n",
    "        n = ord(ch)\n",
    "        if code_a <= n <= code_z: # a~z 사이에 있을 때\n",
    "            cnt[n - code_a] += 1 # a가 몇번 나왔는지 b가 몇번 나왔는지 z가지 카운트를 한다.\n",
    "    # 정규화하기 --- (※3)\n",
    "    total = sum(cnt)  #리스트에 있는 값 모두 더하기\n",
    "    freq = list(map(lambda n: n / total, cnt))\n",
    "    return (freq, lang)\n",
    "    \n",
    "# 각 파일 처리하기\n",
    "def load_files(path):\n",
    "    freqs = []\n",
    "    labels = []\n",
    "    file_list = glob.glob(path)\n",
    "    for fname in file_list:\n",
    "        r = check_freq(fname)\n",
    "        freqs.append(r[0])\n",
    "        labels.append(r[1])\n",
    "    return {\"freqs\":freqs, \"labels\":labels}\n",
    "data = load_files(\"./lang/train/*.txt\")\n",
    "test = load_files(\"./lang/test/*.txt\")\n",
    "# 이후를 대비해서 JSON으로 결과 저장하기\n",
    "with open(\"./lang/freq.json\", \"w\", encoding=\"utf-8\") as fp:\n",
    "    json.dump([data, test], fp)\n",
    "# 학습하기 --- (※4)\n",
    "clf = svm.SVC()\n",
    "clf.fit(data[\"freqs\"], data[\"labels\"])\n",
    "# 예측하기 --- (※5)\n",
    "predict = clf.predict(test[\"freqs\"])\n",
    "# 결과 테스트하기 --- (※6)\n",
    "ac_score = metrics.accuracy_score(test[\"labels\"], predict)\n",
    "cl_report = metrics.classification_report(test[\"labels\"], predict)\n",
    "print(\"정답률 =\", ac_score)\n",
    "print(\"리포트 =\")\n",
    "print(cl_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f76532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c:\\> pip install matplotlib numpy pandas\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "# 알파벳 출현 빈도 데이터 읽어 들이기 --- (※1)\n",
    "with open(\"./lang/freq.json\", \"r\", encoding=\"utf-8\") as fp:\n",
    "    freq = json.load(fp)\n",
    "# 언어마다 계산하기 --- (※2)\n",
    "#print(freq)\n",
    "lang_dic = {}\n",
    "for i, lbl in enumerate(freq[0][\"labels\"]):\n",
    "    fq = freq[0][\"freqs\"][i]\n",
    "    if not (lbl in lang_dic):\n",
    "        lang_dic[lbl] = fq\n",
    "        continue\n",
    "    for idx, v in enumerate(fq):\n",
    "        lang_dic[lbl][idx] = (lang_dic[lbl][idx] + v) / 2 # 그래프를 그릴 수 있게 언어의 빈도를 집계\n",
    "\n",
    "# Pandas의 DataFrame에 데이터 넣기 --- (※3)\n",
    "asclist = [[chr(n) for n in range(97,97+26)]]\n",
    "df = pd.DataFrame(lang_dic, index=asclist) # index를 a~z까지로 사용\n",
    "# 그래프 그리기 --- (※4)\n",
    "plt.style.use('ggplot')\n",
    "df.plot(kind=\"bar\", subplots=True, ylim=(0,0.15))\n",
    "plt.savefig(\"lang-plot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b73d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹 인터페이스 추가하기\n",
    "\n",
    "from sklearn import svm \n",
    "import sklearn.externals \n",
    "import joblib\n",
    "import json\n",
    "# 각 언어의 출현 빈도 데이터(JSON) 읽어 들이기\n",
    "with open(\"./lang/freq.json\", \"r\", encoding=\"utf-8\") as fp:\n",
    "    d = json.load(fp)\n",
    "    data = d[0]\n",
    "# 데이터 학습하기\n",
    "clf = svm.SVC()\n",
    "clf.fit(data[\"freqs\"], data[\"labels\"])\n",
    "# 학습 데이터 저장하기\n",
    "joblib.dump(clf, \"./lang/freq.pkl\")\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb28c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# lang-Webapp.py\n",
    "\n",
    "# python –m http.server --cgi 8080\n",
    "# http://127.0.0.1:8080/으로 경로 확인\n",
    "# 경로에 lang-Webapp.py 저장 \n",
    "# http://localhost:8080/cgi-bin/lang-Webapp.py\n",
    "\n",
    "import cgi, os.path\n",
    "import sklearn.externals \n",
    "import joblib\n",
    "# 학습 데이터 읽어 들이기\n",
    "pklfile = os.path.dirname(__file__) + \"./freq.pkl\"\n",
    "clf = joblib.load(pklfile)\n",
    "# 텍스트 입력 양식 출력하기\n",
    "def show_form(text, msg=\"\"):\n",
    "    print(\"Content-Type: text/html; charset=utf-8\")\n",
    "    print(\"\")\n",
    "    print(\"\"\"\n",
    "        <html><body><form>\n",
    "        <textarea name=\"text\" rows=\"8\" cols=\"40\">{0}</textarea>\n",
    "        <p><input type=\"submit\" value=\"판정\"></p>\n",
    "        <p>{1}</p>\n",
    "        </form></body></html>\n",
    "    \"\"\".format(cgi.escape(text), msg))\n",
    "# 판정하기\n",
    "def detect_lang(text):\n",
    "    # 알파벳 출현 빈도 구하기\n",
    "    text = text.lower() \n",
    "    code_a, code_z = (ord(\"a\"), ord(\"z\"))\n",
    "    cnt = [0 for i in range(26)]\n",
    "    for ch in text:\n",
    "        n = ord(ch) - code_a\n",
    "        if 0 <= n < 26: cnt[n] += 1\n",
    "    total = sum(cnt)\n",
    "    if total == 0: return \"입력이 없습니다\"\n",
    "    freq = list(map(lambda n: n/total, cnt))\n",
    "    # 언어 예측하기\n",
    "    res = clf.predict([freq])\n",
    "    # 언어 코드를 한국어로 변환하기\n",
    "    lang_dic = {\"en\":\"영어\",\"fr\":\"프랑스어\",\n",
    "        \"id\":\"인도네시아어\", \"tl\":\"타갈로그어\"}\n",
    "    return lang_dic[res[0]]\n",
    "# 입력 양식의 값 읽어 들이기\n",
    "form = cgi.FieldStorage()\n",
    "text = form.getvalue(\"text\", default=\"\")\n",
    "msg = \"\"\n",
    "if text != \"\":\n",
    "    lang = detect_lang(text)\n",
    "    msg = \"판정 결과:\" + lang\n",
    "# 입력 양식 출력\n",
    "show_form(text, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7204803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# BMI를 계산해서 레이블을 리턴하는 함수\n",
    "def calc_bmi(h, w):\n",
    "    bmi = w / (h/100) ** 2      #  <BMI> = <몸무게(kg)> / (<키(m)> * <키(m)>)    \n",
    "    if bmi < 18.5: return \"thin\"\n",
    "    if bmi < 25: return \"normal\"\n",
    "    return \"fat\"\n",
    "# 출력 파일 준비하기\n",
    "fp = open(\"bmi.csv\",\"w\",encoding=\"utf-8\")\n",
    "fp.write(\"height,weight,label\\r\\n\")\n",
    "# 무작위로 데이터 생성하기\n",
    "cnt = {\"thin\":0, \"normal\":0, \"fat\":0}\n",
    "for i in range(20000):\n",
    "    h = random.randint(120,200)\n",
    "    w = random.randint(35, 80)\n",
    "    label = calc_bmi(h, w)\n",
    "    cnt[label] += 1\n",
    "    fp.write(\"{0},{1},{2}\\r\\n\".format(h, w, label))   # BMI계산에 따른 데이터 저장\n",
    "fp.close()\n",
    "print(\"ok,\", cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0953e866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       weight  height\n",
      "0        0.73   0.790\n",
      "1        0.40   0.920\n",
      "2        0.51   0.900\n",
      "3        0.55   0.935\n",
      "4        0.64   0.925\n",
      "...       ...     ...\n",
      "19995    0.78   0.770\n",
      "19996    0.59   0.835\n",
      "19997    0.67   0.800\n",
      "19998    0.61   0.995\n",
      "19999    0.76   0.830\n",
      "\n",
      "[20000 rows x 2 columns]\n",
      "정답률 = 0.9966\n",
      "리포트 =\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         fat       1.00      1.00      1.00      1887\n",
      "      normal       0.99      1.00      0.99      1485\n",
      "        thin       1.00      0.99      1.00      1628\n",
      "\n",
      "    accuracy                           1.00      5000\n",
      "   macro avg       1.00      1.00      1.00      5000\n",
      "weighted avg       1.00      1.00      1.00      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# 키와 몸무게 데이터 읽어 들이기 --- (※1)\n",
    "tbl = pd.read_csv(\"bmi.csv\")\n",
    "# 칼럼(열)을 자르고 정규화하기 --- (※2)\n",
    "label = tbl[\"label\"]\n",
    "w = tbl[\"weight\"] / 100 # 최대 100kg라고 가정\n",
    "h = tbl[\"height\"] / 200 # 최대 200cm라고 가정\n",
    "wh = pd.concat([w, h], axis=1) # pandas 를 이용해서  for문 없이 데이터 저장\n",
    "#wh = tbl[[\"weight\",\"height\"]]\n",
    "print(wh)\n",
    "# 학습 전용 데이터와 테스트 전용 데이터로 나누기 --- (※3)\n",
    "data_train, data_test, label_train, label_test = train_test_split(wh, label)\n",
    "# 데이터 학습하기 --- (※4)\n",
    "clf = svm.SVC()\n",
    "clf.fit(data_train, label_train)\n",
    "# 데이터 예측하기 --- (※5)\n",
    "predict = clf.predict(data_test)\n",
    "# 결과 테스트하기 --- (※6)\n",
    "ac_score = metrics.accuracy_score(label_test, predict)\n",
    "cl_report = metrics.classification_report(label_test, predict)\n",
    "print(\"정답률 =\", ac_score)\n",
    "print(\"리포트 =\\n\", cl_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7d256d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Pandas로 CSV 파일 읽어 들이기\n",
    "tbl = pd.read_csv(\"bmi.csv\", index_col=2)\n",
    "# 그래프 그리기 시작\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "# 서브 플롯 전용 - 지정한 레이블을 임의의 색으로 칠하기\n",
    "def scatter(lbl, color):\n",
    "    b = tbl.loc[lbl]\n",
    "    ax.scatter(b[\"weight\"],b[\"height\"], c=color, label=lbl)\n",
    "scatter(\"fat\",    \"red\")\n",
    "scatter(\"normal\", \"yellow\")\n",
    "scatter(\"thin\",   \"purple\")\n",
    "ax.legend() \n",
    "plt.savefig(\"bmi-test.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f190bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 포레스트\n",
    "# 버섯 데이터 셋을 내려 받고 데이터 형식을 확인해 보자.\n",
    "import urllib.request as req\n",
    "local= \"mushroom.csv\"\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
    "req.urlretrieve(url, local)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "285df573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 = 1.0\n",
      "리포트 =\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           e       1.00      1.00      1.00      1088\n",
      "           p       1.00      1.00      1.00       943\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 머신러닝을 할 때는 이를 어떻게 숫자로 변환하는지가 문제이다. \n",
    "# 일단 각각의 기호가 한 글자라는 것에 주목해서 각 기호를 문자 코드로 변환해서 활용하자.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 데이터 읽어 들이기--- (※1)\n",
    "mr = pd.read_csv(\"mushroom.csv\", header=None)\n",
    "# 데이터 내부의 기호를 숫자로 변환하기--- (※2)\n",
    "label = []\n",
    "data = []\n",
    "attr_list = []\n",
    "for row_index, row in mr.iterrows():\n",
    "    label.append(row.iloc[0])\n",
    "    row_data = []\n",
    "    for v in row.iloc[1:]:\n",
    "        row_data.append(ord(v))\n",
    "    data.append(row_data)\n",
    "# 학습 전용과 테스트 전용 데이터로 나누기 --- (※3)\n",
    "data_train, data_test, label_train, label_test = train_test_split(data, label)\n",
    "# 데이터 학습시키기 --- (※4)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(data_train, label_train)\n",
    "# 데이터 예측하기 --- (※5)\n",
    "predict = clf.predict(data_test)\n",
    "# 결과 테스트하기 --- (※6)\n",
    "ac_score = metrics.accuracy_score(label_test, predict)\n",
    "cl_report = metrics.classification_report(label_test, predict)\n",
    "print(\"정답률 =\", ac_score)\n",
    "print(\"리포트 =\\n\", cl_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b5a544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "## 랜덤 포레스트\n",
    "# 머신러닝에서 자주 사용되는 알고리즘으로 \"랜덤 포레스트\"라는 것이 있다. \n",
    "# 이는 학습 전용 데이터를 샘플링해서 여러 개의 의사결정 트리를 만들고, \n",
    "# # 만들어진 의사결정 트리를 기반으로 다수결로 결과를 결정하는 방법이다.\n",
    "# 다수결로 결과를 유도하므로 높은 정밀도를 자랑한다. \n",
    "# 학습 데이터를 무작위로 샘플링해서 만들어진 다수의 ”의사결정 트리“라는 것은 트리 구조를 하고 있는 그래프인데 \n",
    "# 예측과 분류를 수행하는 알고리즘 자체를 의사결정 트리라고 부르기도 한다.\n",
    "\n",
    "import urllib.request as req\n",
    "local= \"mushroom.csv\"   # 독이 있으면 ”p(poisonous)“, 식용이면 ”e(edible)“이다. 첫번째 열\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
    "req.urlretrieve(url, local)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "195aef48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 = 1.0\n",
      "리포트 =\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           e       1.00      1.00      1.00      1043\n",
      "           p       1.00      1.00      1.00       988\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 두 번째 열은 버섯의 머리모양이다.\n",
    "# 네 번째 열은 버섯 머리 색이다. \n",
    "# 머신러닝을 할 때는 이를 숫자로 변환\n",
    "# 각의 기호가 한 글자라는 것에 주목해서 각 기호를 문자 코드로 변환해서 활용하자.\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 데이터 읽어 들이기--- (※1)\n",
    "mr = pd.read_csv(\"mushroom.csv\", header=None)\n",
    "# 데이터 내부의 기호를 숫자로 변환하기--- (※2)\n",
    "label = []\n",
    "data = []\n",
    "attr_list = []\n",
    "for row_index, row in mr.iterrows(): # dataframe에 있는 값을 한행씩 가져오기 위해 사용된 iterrows()함수 \n",
    "    label.append(row.iloc[0]) # 첫번째 열값을 가져온다.  독의 유무\n",
    "    row_data = [] \n",
    "    for v in row.iloc[1:]: \n",
    "        row_data.append(ord(v)) # 두번째 열 부터 문자에 해당하는 숫자로 변환하여 저장\n",
    "    data.append(row_data)\n",
    "\n",
    "# 학습 전용과 테스트 전용 데이터로 나누기 --- (※3)\n",
    "data_train, data_test, label_train, label_test = train_test_split(data, label)\n",
    "# 데이터 학습시키기 --- (※4)\n",
    "clf = RandomForestClassifier() #  램덤 포레스트객체 생성\n",
    "clf.fit(data_train, label_train)\n",
    "# 데이터 예측하기 --- (※5)\n",
    "predict = clf.predict(data_test)\n",
    "# 결과 테스트하기 --- (※6)\n",
    "ac_score = metrics.accuracy_score(label_test, predict)\n",
    "cl_report = metrics.classification_report(label_test, predict)\n",
    "print(\"정답률 =\", ac_score)\n",
    "print(\"리포트 =\\n\", cl_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5942e668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 데이터 읽어 들이기\n",
    "mr = pd.read_csv(\"mushroom.csv\", header=None)\n",
    "# 데이터 내부의 분류 변수 전개하기\n",
    "label = []\n",
    "data = []\n",
    "attr_list = []\n",
    "for row_index, row in mr.iterrows():\n",
    "    label.append(row.iloc[0])\n",
    "    print(row.iloc[1:])\n",
    "    for col, v in enumerate(row.iloc[1:]):\n",
    "        if row_index == 0:  # label : 식용인지 아닌지 : 제외\n",
    "            attr = {\"dic\": {}, \"cnt\":0}\n",
    "            attr_list.append(attr)\n",
    "        else:\n",
    "            attr = attr_list[col]\n",
    "        \n",
    "        # 버섯의 특징 기호를 배열로 나타내기\n",
    "        d = [0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "        if v in attr[\"dic\"]:\n",
    "            idx = attr[\"dic\"][v]\n",
    "        else:\n",
    "            idx = attr[\"cnt\"]\n",
    "            attr[\"dic\"][v] = idx\n",
    "            attr[\"cnt\"] += 1\n",
    "        d[idx] = 1\n",
    "        exdata += d\n",
    "    data.append(exdata)\n",
    "# 학습 전용 데이터와 테스트 전용 데이터로 나누기\n",
    "data_train, data_test, label_train, label_test = \\\n",
    "train_test_split(data, label)\n",
    "# 데이터 학습시키기\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(data_train, label_train)\n",
    "# 데이터 예측하기\n",
    "predict = clf.predict(data_test)\n",
    "# 결과 테스트하기\n",
    "ac_score = metrics.accuracy_score(label_test, predict)\n",
    "print(\"정답률 =\", ac_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec48f72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 검증하는 방법\n",
    "from sklearn import svm, metrics\n",
    "import random, re\n",
    "# 붓꽃의 CSV 파일 읽어 들이기 --- (※1)\n",
    "lines = open('iris.csv', 'r', encoding='utf-8').read().split(\"\\n\")\n",
    "f_tonum = lambda n : float(n) if re.match(r'^[0-9\\.]+$', n) else n\n",
    "f_cols  = lambda li: list(map(f_tonum,li.strip().split(',')))\n",
    "csv = list(map(f_cols, lines))\n",
    "del csv[0] # 헤더 제거하기\n",
    "random.shuffle(csv) # 데이터 섞기\n",
    "# 데이터를 K개로 분할하기 --- (※2)\n",
    "K = 5 \n",
    "csvk = [ [] for i in range(K) ]\n",
    "for i in range(len(csv)):\n",
    "    csvk[i % K].append(csv[i])\n",
    "# 리스트를 훈련 전용 데이터와 테스트 전용 데이터로 분할하는 함수\n",
    "def split_data_label(rows):\n",
    "    data = []; label = []\n",
    "    for row in rows:\n",
    "        data.append(row[0:4])\n",
    "        label.append(row[4])\n",
    "    return (data, label)\n",
    "# 정답률 구하기 --- (※3)\n",
    "def calc_score(test, train):\n",
    "    test_f, test_l = split_data_label(test)\n",
    "    train_f, train_l = split_data_label(train)\n",
    "    # 학습시키고 정답률 구하기\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(train_f, train_l)\n",
    "    pre = clf.predict(test_f)\n",
    "    return metrics.accuracy_score(test_l, pre)\n",
    "# K개로 분할해서 정답률 구하기 --- (※4)\n",
    "score_list = []\n",
    "for testc in csvk:\n",
    "    # testc 이외의 데이터를 훈련 전용 데이터로 사용하기\n",
    "    trainc = []\n",
    "    for i in csvk:\n",
    "        if i != testc: trainc += i\n",
    "    sc = calc_score(testc, trainc)\n",
    "    score_list.append(sc)\n",
    "print(\"각각의 정답률 =\", score_list)\n",
    "print(\"평균 정답률 =\", sum(score_list) / len(score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d9d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm, metrics, model_selection\n",
    "import random, re\n",
    "# 붓꽃의 CSV 데이터 읽어 들이기 --- (※1)\n",
    "csv = pd.read_csv('iris.csv')\n",
    "# 리스트를 훈련 전용 데이터와 테스트 전용 데이터로 분할하기 --- (※2)\n",
    "data = csv[[\"SepalLength\",\"SepalWidth\",\"PetalLength\",\"PetalWidth\"]]\n",
    "label = csv[\"Name\"]\n",
    "# 크로스 밸리데이션하기 --- (※3)\n",
    "clf = svm.SVC()\n",
    "scores = model_selection.cross_val_score(clf, data, label, cv=5)\n",
    "print(\"각각의 정답률 =\", scores)\n",
    "print(\"평균 정답률 =\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351ce0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그리드 서치\n",
    "import pandas as pd\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# MNIST 학습 데이터 읽어 들이기 --- (※1)\n",
    "train_csv = pd.read_csv(\"./mnist/train.csv\")\n",
    "test_csv  = pd.read_csv(\"./mnist/t10k.csv\")\n",
    "# 필요한 열 추출하기 --- (※2)\n",
    "train_label = train_csv.iloc[:, 0]\n",
    "train_data  = train_csv.iloc[:, 1:577]\n",
    "test_label  = test_csv.iloc[:, 0]\n",
    "test_data   = test_csv.iloc[:, 1:577]\n",
    "print(\"학습 데이터의 수 =\", len(train_label))\n",
    "# 그리드 서치 매개변수 설정 --- (※3)\n",
    "params = [\n",
    "    {\"C\": [1,10,100,1000], \"kernel\":[\"linear\"]},\n",
    "    {\"C\": [1,10,100,1000], \"kernel\":[\"rbf\"], \"gamma\":[0.001, 0.0001]}\n",
    "]\n",
    "# 그리드 서치 수행 --- (※4)\n",
    "clf = GridSearchCV( svm.SVC(), params, n_jobs=-1 )\n",
    "clf.fit(train_data, train_label)\n",
    "print(\"학습기 =\", clf.best_estimator_)\n",
    "# 테스트 데이터 확인하기 --- (※5)\n",
    "pre = clf.predict(test_data)\n",
    "ac_score = metrics.accuracy_score(pre, test_label)\n",
    "print(\"정답률 =\",ac_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cf0d52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6234\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 개요.\n",
    "# TensorFlow 임포트 --- (※1)\n",
    "import tensorflow as tf\n",
    "\n",
    "# 상수 정의 --- (※2)\n",
    "a = tf.constant(1234)\n",
    "b = tf.constant(5000)\n",
    "\n",
    "\n",
    "# 계산 정의 --- (※3)\n",
    "@tf.function\n",
    "def add_op(a, b):\n",
    "    return a + b\n",
    "\n",
    "\n",
    "# 세션 시작하기 --- (※4)\n",
    "res = add_op(a, b).numpy()        # 식 평가하기\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "882bf55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow 읽어 들이기 --- (※1)\n",
    "import tensorflow as tf\n",
    "\n",
    "# 상수 정의하기 --- (※2)\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "c = tf.constant(4)\n",
    "\n",
    "\n",
    "# 연산 정의하기 --- (※3)\n",
    "@tf.function\n",
    "def calc1_op():\n",
    "    return a + b * c\n",
    "\n",
    "@tf.function\n",
    "def calc2_op():\n",
    "    return (a + b) * c\n",
    "\n",
    "\n",
    "# 세션 시작하기 --- (※4)\n",
    "res1 = calc1_op().numpy() # 식 평가하기\n",
    "print(res1)\n",
    "res2 = calc2_op().numpy() # 식 평가하기\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e38400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# 상수 정의하기 --- (※1)\n",
    "a = tf.constant(120, name=\"a\")\n",
    "b = tf.constant(130, name=\"b\")\n",
    "c = tf.constant(140, name=\"c\")\n",
    "# 변수 정의하기 --- (※2)\n",
    "v = tf.Variable(0, name=\"v\")\n",
    "# 데이터 플로우 그래프 정의하기 --- (※3)\n",
    "calc_op = a + b + c\n",
    "assign_op = tf.assign(v, calc_op)\n",
    "# 세션 실행하기 --- (※4)\n",
    "sess = tf.Session()\n",
    "sess.run(assign_op)\n",
    "# v의 내용 출력하기 --- (※5)\n",
    "print( sess.run(v) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68dac04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 6]\n",
      "[20 40 20]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# 플레이스홀더 정의하기 --- (※1)\n",
    "a = tf.placeholder(tf.int32, [3]) # 정수 자료형 3개를 가진 배열\n",
    "# 배열을 모든 값을 2배하는 연산 정의하기 --- (※2)\n",
    "b = tf.constant(2)\n",
    "x2_op = a * b\n",
    "# 세션 시작하기 --- (※3)\n",
    "sess = tf.Session()\n",
    "# 플레이스홀더에 값을 넣고 실행하기 --- (※4)\n",
    "r1 = sess.run(x2_op, feed_dict={ a:[1, 2, 3] })\n",
    "print(r1)\n",
    "r2 = sess.run(x2_op, feed_dict={ a:[10, 20, 10] })\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c31e974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30 40 50]\n",
      "[100 200]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# 플레이스홀더 정의하기 --- (※1)\n",
    "a = tf.placeholder(tf.int32, [None]) # 배열의 크기를 None으로 지정\n",
    "# 배열의 모든 값을 10배하는 연산 정의하기 \n",
    "b = tf.constant(10)\n",
    "x10_op = a * b\n",
    "# 세션 시작하기 \n",
    "sess = tf.Session()\n",
    "# 플레이스홀더에 값을 넣어 실행하기 --- (※2)\n",
    "r1 = sess.run(x10_op, feed_dict={a: [1,2,3,4,5]})\n",
    "print(r1)\n",
    "r2 = sess.run(x10_op, feed_dict={a: [10,20]})\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2a8c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step= 0 cre= 109.39801 acc= 0.2926\n",
      "step= 500 cre= 58.282223 acc= 0.868\n",
      "step= 1000 cre= 46.247185 acc= 0.9282\n",
      "step= 1500 cre= 38.766785 acc= 0.944\n",
      "step= 2000 cre= 36.01812 acc= 0.9582\n",
      "step= 2500 cre= 34.1697 acc= 0.9604\n",
      "step= 3000 cre= 31.909721 acc= 0.9654\n",
      "정답률 = 0.9686\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# 키, 몸무게, 레이블이 적힌 CSV 파일 읽어 들이기 --- (※1)\n",
    "csv = pd.read_csv(\"bmi.csv\")\n",
    "# 데이터 정규화 --- (※2)\n",
    "csv[\"height\"] = csv[\"height\"] / 200\n",
    "csv[\"weight\"] = csv[\"weight\"] / 100\n",
    "# 레이블을 배열로 변환하기 --- (※3)\n",
    "# - thin=(1,0,0) / normal=(0,1,0) / fat=(0,0,1)\n",
    "bclass = {\"thin\": [1,0,0], \"normal\": [0,1,0], \"fat\": [0,0,1]}\n",
    "csv[\"label_pat\"] = csv[\"label\"].apply(lambda x : np.array(bclass[x]))\n",
    "# 테스트를 위한 데이터 분류 --- (※4)\n",
    "test_csv = csv[15000:20000]\n",
    "test_pat = test_csv[[\"weight\",\"height\"]]\n",
    "test_ans = list(test_csv[\"label_pat\"])\n",
    "# 데이터 플로우 그래프 구축하기 --- (※5)\n",
    "# 플레이스홀더 선언하기\n",
    "x  = tf.placeholder(tf.float32, [None, 2]) # 키와 몸무게 데이터 넣기\n",
    "y_ = tf.placeholder(tf.float32, [None, 3]) # 정답 레이블 넣기\n",
    "# 변수 선언하기 --- (※6)\n",
    "W = tf.Variable(tf.zeros([2, 3])); # 가중치\n",
    "b = tf.Variable(tf.zeros([3])); # 바이어스\n",
    "# 소프트맥스 회귀 정의하기 --- (※7)\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "# 모델 훈련하기 --- (※8)\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(cross_entropy)\n",
    "# 정답률 구하기\n",
    "predict = tf.equal(tf.argmax(y, 1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(predict, tf.float32))\n",
    "# 세션 시작하기\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) # 변수 초기화하기\n",
    "# 학습시키기\n",
    "for step in range(3500):\n",
    "    i = (step * 100) % 14000\n",
    "    rows = csv[1 + i : 1 + i + 100]\n",
    "    x_pat = rows[[\"weight\",\"height\"]]\n",
    "    y_ans = list(rows[\"label_pat\"])\n",
    "    fd = {x: x_pat, y_: y_ans}\n",
    "    sess.run(train, feed_dict=fd)\n",
    "    if step % 500 == 0:\n",
    "        cre = sess.run(cross_entropy, feed_dict=fd)\n",
    "        acc = sess.run(accuracy, feed_dict={x: test_pat, y_: test_ans})\n",
    "        print(\"step=\", step, \"cre=\", cre, \"acc=\", acc)\n",
    "# 최종적인 정답률 구하기\n",
    "acc = sess.run(accuracy, feed_dict={x: test_pat, y_: test_ans})\n",
    "print(\"정답률 =\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f37e60cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "# 5-5.TensorBoard로 시각화하기\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# 데이터 플로우 그래프 구축하기 --- (※1)\n",
    "a = tf.constant(20, name=\"a\")\n",
    "b = tf.constant(30, name=\"b\")\n",
    "mul_op = a * b\n",
    "\n",
    "# 세션 생성하기 --- (※2)\n",
    "sess = tf.Session()\n",
    "\n",
    "# TensorBoard 사용하기 --- (※3)\n",
    "tw = tf.summary.FileWriter(\"log_dir\", graph=sess.graph)\n",
    "\n",
    "# 세션 실행하기  --- (※4)\n",
    "print(sess.run(mul_op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd637b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60100\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# 상수와 변수 선언하기 --- (※1)\n",
    "a = tf.constant(100, name=\"a\")\n",
    "b = tf.constant(200, name=\"b\")\n",
    "c = tf.constant(300, name=\"c\")\n",
    "v = tf.Variable(0, name=\"v\")\n",
    "\n",
    "# 곱셈을 수행하는 그래프 정의하기 --- (※2)\n",
    "calc_op = a + b * c \n",
    "assign_op = tf.assign(v, calc_op)\n",
    "\n",
    "# 세션 생성하기 --- (※3)\n",
    "sess = tf.Session()\n",
    "\n",
    "# TensorBoard 사용하기 --- (※4)\n",
    "tw = tf.summary.FileWriter(\"log_dir\", graph=sess.graph)\n",
    "\n",
    "# 세션 실행하기  --- (※5)\n",
    "sess.run(assign_op)\n",
    "print(sess.run(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89479d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step= 0 cre= 109.39801 acc= 0.2926\n",
      "step= 500 cre= 58.282223 acc= 0.868\n",
      "step= 1000 cre= 46.247185 acc= 0.9282\n",
      "step= 1500 cre= 38.766785 acc= 0.944\n",
      "step= 2000 cre= 36.01812 acc= 0.9582\n",
      "step= 2500 cre= 34.1697 acc= 0.9604\n",
      "step= 3000 cre= 31.909721 acc= 0.9654\n",
      "정답률= 0.9686\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# 키, 몸무게, 레이블이 적힌 CSV 파일 읽어 들이기\n",
    "csv = pd.read_csv(\"bmi.csv\")\n",
    "# 데이터 정규화 --- (※2)\n",
    "csv[\"height\"] = csv[\"height\"] / 200\n",
    "csv[\"weight\"] = csv[\"weight\"] / 100\n",
    "# 레이블을 배열로 변환하기\n",
    "# - thin=(1,0,0) / normal=(0,1,0) / fat=(0,0,1)\n",
    "bclass = {\"thin\": [1,0,0], \"normal\": [0,1,0], \"fat\": [0,0,1]}\n",
    "csv[\"label_pat\"] = csv[\"label\"].apply(lambda x : np.array(bclass[x]))\n",
    "\n",
    "# 테스트를 위한 데이터 분류\n",
    "test_csv = csv[15000:20000]\n",
    "test_pat = test_csv[[\"weight\",\"height\"]]\n",
    "test_ans = list(test_csv[\"label_pat\"])\n",
    "\n",
    "# 플레이스홀더로 이름 붙이기\n",
    "x  = tf.placeholder(tf.float32, [None, 2], name=\"x\") \n",
    "y_ = tf.placeholder(tf.float32, [None, 3], name=\"y_\") \n",
    "\n",
    "# interface 부분을 스코프로 묶기\n",
    "with tf.name_scope('interface') as scope:\n",
    "    W = tf.Variable(tf.zeros([2, 3]), name=\"W\"); # 가중치\n",
    "    b = tf.Variable(tf.zeros([3]), name=\"b\"); # 바이어스\n",
    "    # 소프트맥스 회귀 정의 --- (※7)\n",
    "    with tf.name_scope('softmax') as scope:\n",
    "        y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "#  loss 계산을 스코프로 묶기\n",
    "with tf.name_scope('loss') as scope:\n",
    "    cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n",
    "\n",
    "# training 계산을 스코프로 묶기\n",
    "with tf.name_scope('training') as scope:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    train = optimizer.minimize(cross_entropy)\n",
    "\n",
    "#  accuracy 계산을 스코프로 묶기\n",
    "with tf.name_scope('accuracy') as scope:\n",
    "    predict = tf.equal(tf.argmax(y, 1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(predict, tf.float32))\n",
    "\n",
    "# 세션 시작하기\n",
    "with tf.Session() as sess:\n",
    "    tw = tf.summary.FileWriter(\"log_dir\", graph=sess.graph)\n",
    "    sess.run(tf.global_variables_initializer()) # 변수 초기화하기\n",
    "    # 테스트 데이터를 이용해 학습하기\n",
    "    for step in range(3500):\n",
    "        i = (step * 100) % 14000\n",
    "        rows = csv[1 + i : 1 + i + 100]\n",
    "        x_pat = rows[[\"weight\",\"height\"]]\n",
    "        y_ans = list(rows[\"label_pat\"])\n",
    "        fd = {x: x_pat, y_: y_ans}\n",
    "        sess.run(train, feed_dict=fd)\n",
    "        if step % 500 == 0:\n",
    "            cre = sess.run(cross_entropy, feed_dict=fd)\n",
    "            acc = sess.run(accuracy, feed_dict={x: test_pat, y_: test_ans})\n",
    "            print(\"step=\", step, \"cre=\", cre, \"acc=\", acc)\n",
    "\n",
    "    # 최종적인 정답률 구하기\n",
    "    acc = sess.run(accuracy, feed_dict={x: test_pat, y_: test_ans})\n",
    "    print(\"정답률=\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b821dad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_3400/3006289573.py:2: read_data_sets (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as: tensorflow_datasets.load('mnist')\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\examples\\tutorials\\mnist\\input_data.py:296: _maybe_download (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\examples\\tutorials\\mnist\\input_data.py:299: _extract_images (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\examples\\tutorials\\mnist\\input_data.py:304: _extract_labels (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\examples\\tutorials\\mnist\\input_data.py:112: _dense_to_one_hot (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\examples\\tutorials\\mnist\\input_data.py:328: _DataSet.__init__ (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/_DataSet.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "#AppData\\Local\\Programs\\Python\\Python38\\Lib\\site-packages\\tensorflow\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data \n",
    "mnist = input_data.read_data_sets(\"mnist/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e3864a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1096: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "step= 0 loss= 656.41833 acc= 0.1371\n",
      "step= 100 loss= 47.71647 acc= 0.8445\n",
      "step= 200 loss= 21.471935 acc= 0.9036\n",
      "step= 300 loss= 20.927895 acc= 0.9281\n",
      "step= 400 loss= 23.147497 acc= 0.9397\n",
      "step= 500 loss= 19.85801 acc= 0.9477\n",
      "step= 600 loss= 10.831198 acc= 0.9536\n",
      "step= 700 loss= 14.848038 acc= 0.9577\n",
      "step= 800 loss= 8.892637 acc= 0.9596\n",
      "step= 900 loss= 13.045961 acc= 0.9588\n",
      "step= 1000 loss= 16.49296 acc= 0.9617\n",
      "step= 1100 loss= 13.013065 acc= 0.9627\n",
      "step= 1200 loss= 8.026761 acc= 0.9669\n",
      "step= 1300 loss= 3.2778964 acc= 0.9657\n",
      "step= 1400 loss= 7.940196 acc= 0.9694\n",
      "step= 1500 loss= 7.23276 acc= 0.9682\n",
      "step= 1600 loss= 5.3530445 acc= 0.9687\n",
      "step= 1700 loss= 5.395192 acc= 0.9735\n",
      "step= 1800 loss= 3.9261417 acc= 0.9726\n",
      "step= 1900 loss= 3.1159205 acc= 0.9738\n",
      "step= 2000 loss= 3.413362 acc= 0.9743\n",
      "step= 2100 loss= 8.862082 acc= 0.9764\n",
      "step= 2200 loss= 6.7668676 acc= 0.9763\n",
      "step= 2300 loss= 7.8077626 acc= 0.977\n",
      "step= 2400 loss= 3.1825953 acc= 0.978\n",
      "step= 2500 loss= 7.4614434 acc= 0.9783\n",
      "step= 2600 loss= 7.369191 acc= 0.9784\n",
      "step= 2700 loss= 5.7635136 acc= 0.9774\n",
      "step= 2800 loss= 2.5763164 acc= 0.9771\n",
      "step= 2900 loss= 0.47142226 acc= 0.9803\n",
      "step= 3000 loss= 10.443891 acc= 0.9805\n",
      "step= 3100 loss= 6.361445 acc= 0.9812\n",
      "step= 3200 loss= 0.9413877 acc= 0.9823\n",
      "step= 3300 loss= 8.811688 acc= 0.9814\n",
      "step= 3400 loss= 4.335296 acc= 0.9835\n",
      "step= 3500 loss= 5.1126966 acc= 0.9812\n",
      "step= 3600 loss= 6.8143034 acc= 0.982\n",
      "step= 3700 loss= 1.3953657 acc= 0.9827\n",
      "step= 3800 loss= 1.9285369 acc= 0.9817\n",
      "step= 3900 loss= 2.10119 acc= 0.9839\n",
      "step= 4000 loss= 1.062257 acc= 0.9845\n",
      "step= 4100 loss= 0.28711414 acc= 0.9839\n",
      "step= 4200 loss= 10.019136 acc= 0.9848\n",
      "step= 4300 loss= 2.6360884 acc= 0.9843\n",
      "step= 4400 loss= 0.563136 acc= 0.986\n",
      "step= 4500 loss= 0.72273445 acc= 0.984\n",
      "step= 4600 loss= 1.6716833 acc= 0.9831\n",
      "step= 4700 loss= 1.8075445 acc= 0.9858\n",
      "step= 4800 loss= 2.9454367 acc= 0.9858\n",
      "step= 4900 loss= 2.6107154 acc= 0.9855\n",
      "step= 5000 loss= 5.3210597 acc= 0.9864\n",
      "step= 5100 loss= 1.8755355 acc= 0.9861\n",
      "step= 5200 loss= 3.0324235 acc= 0.9874\n",
      "step= 5300 loss= 0.5460557 acc= 0.9866\n",
      "step= 5400 loss= 0.29631758 acc= 0.9877\n",
      "step= 5500 loss= 0.38912246 acc= 0.9884\n",
      "step= 5600 loss= 5.7353625 acc= 0.9872\n",
      "step= 5700 loss= 2.7682242 acc= 0.9863\n",
      "step= 5800 loss= 3.8775032 acc= 0.9881\n",
      "step= 5900 loss= 10.191284 acc= 0.988\n",
      "step= 6000 loss= 0.9406376 acc= 0.9857\n",
      "step= 6100 loss= 0.5209474 acc= 0.9881\n",
      "step= 6200 loss= 1.679852 acc= 0.9884\n",
      "step= 6300 loss= 1.5216271 acc= 0.9884\n",
      "step= 6400 loss= 1.1874174 acc= 0.9888\n",
      "step= 6500 loss= 1.2088443 acc= 0.9885\n",
      "step= 6600 loss= 5.4549036 acc= 0.987\n",
      "step= 6700 loss= 1.3437915 acc= 0.9882\n",
      "step= 6800 loss= 0.32410228 acc= 0.989\n",
      "step= 6900 loss= 1.695641 acc= 0.9873\n",
      "step= 7000 loss= 1.0176717 acc= 0.9892\n",
      "step= 7100 loss= 0.21464318 acc= 0.9881\n",
      "step= 7200 loss= 0.32266253 acc= 0.9886\n",
      "step= 7300 loss= 0.40804857 acc= 0.9895\n",
      "step= 7400 loss= 2.9630127 acc= 0.9886\n",
      "step= 7500 loss= 1.262109 acc= 0.9886\n",
      "step= 7600 loss= 1.4266502 acc= 0.9893\n",
      "step= 7700 loss= 0.98706394 acc= 0.9885\n",
      "step= 7800 loss= 2.5044453 acc= 0.9884\n",
      "step= 7900 loss= 0.5266502 acc= 0.9895\n",
      "step= 8000 loss= 2.5225704 acc= 0.9885\n",
      "step= 8100 loss= 3.7256637 acc= 0.9883\n",
      "step= 8200 loss= 5.1326065 acc= 0.9884\n",
      "step= 8300 loss= 1.6779468 acc= 0.9889\n",
      "step= 8400 loss= 1.4128618 acc= 0.9896\n",
      "step= 8500 loss= 0.61219686 acc= 0.9895\n",
      "step= 8600 loss= 0.0975112 acc= 0.9901\n",
      "step= 8700 loss= 7.289333 acc= 0.99\n",
      "step= 8800 loss= 0.32050383 acc= 0.9904\n",
      "step= 8900 loss= 5.1538935 acc= 0.9895\n",
      "step= 9000 loss= 2.1556056 acc= 0.9898\n",
      "step= 9100 loss= 1.0432423 acc= 0.9896\n",
      "step= 9200 loss= 0.23252028 acc= 0.9889\n",
      "step= 9300 loss= 0.12846813 acc= 0.9894\n",
      "step= 9400 loss= 0.15521583 acc= 0.9901\n",
      "step= 9500 loss= 0.23956528 acc= 0.9894\n",
      "step= 9600 loss= 0.1995117 acc= 0.9896\n",
      "step= 9700 loss= 0.21152046 acc= 0.989\n",
      "step= 9800 loss= 0.12615958 acc= 0.9896\n",
      "step= 9900 loss= 0.38765624 acc= 0.9905\n",
      "정답률 = 0.9904\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data \n",
    "tf.disable_v2_behavior()\n",
    "# 이 예제는 텐서플로 1.14에서 작동합니다.\n",
    "# 텐서플로 2.X 환경은 keras-mnist.py 예제를 참고하시기 바랍니다.\n",
    "\n",
    "# MNIST 손글씨 이미지 데이터 읽어 들이기 --- (※1)\n",
    "mnist = input_data.read_data_sets(\"mnist/\", one_hot=True)\n",
    "pixels = 28 * 28 # 28x28 픽셀\n",
    "nums = 10 # 0-9 사이의 카테고리\n",
    "# 플레이스홀더 정의하기 --- (※2)\n",
    "x  = tf.placeholder(tf.float32, shape=(None, pixels), name=\"x\") # 이미지 데이터\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, nums), name=\"y_\")  # 정답 레이블\n",
    "# 가중치와 바이어스를 초기화하는 함수 --- (※3)\n",
    "def weight_variable(name, shape):\n",
    "    W_init = tf.truncated_normal(shape, stddev=0.1)\n",
    "    W = tf.Variable(W_init, name=\"W_\"+name)\n",
    "    return W\n",
    "def bias_variable(name, size):\n",
    "    b_init = tf.constant(0.1, shape=[size])\n",
    "    b = tf.Variable(b_init, name=\"b_\"+name)\n",
    "    return b\n",
    "# 합성곱 계층을 만드는 함수 --- (※4)\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "# 최대 풀링층을 만드는 함수 --- (※5)\n",
    "def max_pool(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1],\n",
    "        strides=[1,2,2,1], padding='SAME')\n",
    "# 합성곱층1 --- (※6)\n",
    "with tf.name_scope('conv1') as scope:\n",
    "    W_conv1 = weight_variable('conv1', [5, 5, 1, 32])\n",
    "    b_conv1 = bias_variable('conv1', 32)\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "# 풀링층1 ---- (※7)\n",
    "with tf.name_scope('pool1') as scope:\n",
    "    h_pool1 = max_pool(h_conv1)\n",
    "# 합성곱층2 --- (※8)\n",
    "with tf.name_scope('conv2') as scope:\n",
    "    W_conv2 = weight_variable('conv2', [5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable('conv2', 64)\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "# 풀링층2 --- (※9)\n",
    "with tf.name_scope('pool2') as scope:\n",
    "    h_pool2 = max_pool(h_conv2)\n",
    "# 전결합층 --- (※10)\n",
    "with tf.name_scope('fully_connected') as scope:\n",
    "    n = 7 * 7 * 64\n",
    "    W_fc = weight_variable('fc', [n, 1024])\n",
    "    b_fc = bias_variable('fc', 1024)\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, n])\n",
    "    h_fc = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc) + b_fc)        \n",
    "# 드롭아웃(과잉 적합) 막기 --- (※11)\n",
    "with tf.name_scope('dropout') as scope:\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc_drop = tf.nn.dropout(h_fc, keep_prob)\n",
    "# 출력층 --- (※12)\n",
    "with tf.name_scope('readout') as scope:\n",
    "    W_fc2 = weight_variable('fc2', [1024, 10])\n",
    "    b_fc2 = bias_variable('fc2', 10)\n",
    "    y_conv = tf.nn.softmax(tf.matmul(h_fc_drop, W_fc2) + b_fc2)\n",
    "# 모델 학습시키기 --- (※13)\n",
    "with tf.name_scope('loss') as scope:\n",
    "    cross_entoropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n",
    "with tf.name_scope('training') as scope:\n",
    "    optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "    train_step = optimizer.minimize(cross_entoropy)\n",
    "# 모델 평가하기 --- (※14)\n",
    "with tf.name_scope('predict') as scope:\n",
    "    predict_step = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "    accuracy_step = tf.reduce_mean(tf.cast(predict_step, tf.float32))\n",
    "# feed_dict 설정하기 --- (※15)\n",
    "def set_feed(images, labels, prob):\n",
    "    return {x: images, y_: labels, keep_prob: prob}\n",
    "# 세션 시작하기 --- (※16)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # TensorBoard 준비하기\n",
    "    tw = tf.summary.FileWriter('log_dir', graph=sess.graph)\n",
    "    # 테스트 전용 피드 만들기\n",
    "    test_fd = set_feed(mnist.test.images, mnist.test.labels, 1)\n",
    "    # 학습 시작하기 ---- (※17)\n",
    "    for step in range(10000):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        fd = set_feed(batch[0], batch[1], 0.5)\n",
    "        _, loss = sess.run([train_step, cross_entoropy], feed_dict=fd)\n",
    "        if step % 100 == 0:\n",
    "            acc = sess.run(accuracy_step, feed_dict=test_fd)\n",
    "            print(\"step=\", step, \"loss=\", loss, \"acc=\", acc)\n",
    "    # 최종적인 결과 출력하기\n",
    "    acc = sess.run(accuracy_step, feed_dict=test_fd)\n",
    "    print(\"정답률 =\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15ca8d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "11501568/11490434 [==============================] - 1s 0us/step\n",
      "Train on 60000 samples\n",
      "60000/60000 [==============================] - 9s 143us/sample - loss: 0.2193 - acc: 0.9326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 0.10841566259423271\n",
      "accuracy= 0.9654\n"
     ]
    }
   ],
   "source": [
    "#  Keras로 다양한 딥러닝 해보기\n",
    "\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import utils\n",
    "# MNIST 데이터 읽어 들이기 --- (※1)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# 데이터를 float32 자료형으로 변환하고 정규화하기 --- (※2)\n",
    "X_train = X_train.reshape(60000, 784).astype('float32')\n",
    "X_test  = X_test.reshape(10000, 784).astype('float')\n",
    "X_train /= 255\n",
    "X_test  /= 255\n",
    "# 레이블 데이터를 0-9까지의 카테고리를 나타내는 배열로 변환하기 --- (※2a)\n",
    "y_train = utils.to_categorical(y_train, 10)\n",
    "y_test  = utils.to_categorical(y_test, 10)\n",
    "# 모델 구조 정의하기 --- (※3)\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "# 모델 구축하기 --- (※4)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy'])\n",
    "# 데이터 훈련하기 --- (※5)\n",
    "hist = model.fit(X_train, y_train)\n",
    "# 테스트 데이터로 평가하기 --- (※6)\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8319a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13500 samples, validate on 1500 samples\n",
      "Epoch 1/20\n",
      "13500/13500 [==============================] - 1s 63us/sample - loss: 0.5086 - acc: 0.7850 - val_loss: 0.3523 - val_acc: 0.8400\n",
      "Epoch 2/20\n",
      "13500/13500 [==============================] - 1s 53us/sample - loss: 0.2447 - acc: 0.9045 - val_loss: 0.1400 - val_acc: 0.9807\n",
      "Epoch 3/20\n",
      "13500/13500 [==============================] - 1s 42us/sample - loss: 0.1927 - acc: 0.9217 - val_loss: 0.1096 - val_acc: 0.9727\n",
      "Epoch 4/20\n",
      "13500/13500 [==============================] - 1s 45us/sample - loss: 0.1681 - acc: 0.9261 - val_loss: 0.0943 - val_acc: 0.9793\n",
      "Epoch 5/20\n",
      "13500/13500 [==============================] - 1s 49us/sample - loss: 0.1510 - acc: 0.9353 - val_loss: 0.0887 - val_acc: 0.9693\n",
      "Epoch 6/20\n",
      "13500/13500 [==============================] - 1s 45us/sample - loss: 0.1454 - acc: 0.9407 - val_loss: 0.0857 - val_acc: 0.9667\n",
      "Epoch 7/20\n",
      "13500/13500 [==============================] - 1s 47us/sample - loss: 0.1318 - acc: 0.9447 - val_loss: 0.0770 - val_acc: 0.9707\n",
      "Epoch 8/20\n",
      "13500/13500 [==============================] - 1s 45us/sample - loss: 0.1287 - acc: 0.9422 - val_loss: 0.0626 - val_acc: 0.9820\n",
      "Epoch 9/20\n",
      "13500/13500 [==============================] - 1s 42us/sample - loss: 0.1273 - acc: 0.9498 - val_loss: 0.0601 - val_acc: 0.9847\n",
      "Epoch 10/20\n",
      "13500/13500 [==============================] - 1s 47us/sample - loss: 0.1201 - acc: 0.9472 - val_loss: 0.0545 - val_acc: 0.9927\n",
      "Epoch 11/20\n",
      "13500/13500 [==============================] - 1s 49us/sample - loss: 0.1166 - acc: 0.9509 - val_loss: 0.0589 - val_acc: 0.9827\n",
      "Epoch 12/20\n",
      "13500/13500 [==============================] - 1s 48us/sample - loss: 0.1208 - acc: 0.9490 - val_loss: 0.0560 - val_acc: 0.9873\n",
      "loss= 0.061688474319677014\n",
      "accuracy= 0.9825965\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd, numpy as np\n",
    "# BMI 데이터를 읽어 들이고 정규화하기 --- (※1)\n",
    "csv = pd.read_csv(\"bmi.csv\")\n",
    "# 몸무게와 키 데이터\n",
    "csv[\"weight\"] /= 100\n",
    "csv[\"height\"] /= 200\n",
    "X = csv[[\"weight\", \"height\"]]  # --- (※1a)\n",
    "# 레이블\n",
    "bclass = {\"thin\":[1,0,0], \"normal\":[0,1,0], \"fat\":[0,0,1]}\n",
    "y = np.empty((20000,3))\n",
    "for i, v in enumerate(csv[\"label\"]):\n",
    "    y[i] = bclass[v]\n",
    "# 훈련 전용 데이터와 테스트 전용 데이터로 나누기 --- (※2)\n",
    "X_train, y_train = X[1:15001], y[1:15001]\n",
    "X_test,  y_test  = X[15001:20001], y[15001:20001] \n",
    "# 모델 구조 정의하기 --- (※3)\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(2,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "# 모델 구축하기 --- (※4)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=\"rmsprop\",\n",
    "    metrics=['accuracy'])\n",
    "# 데이터 훈련하기 --- (※5)\n",
    "hist = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=100,\n",
    "    epochs=20,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=2)],\n",
    "    verbose=1)\n",
    "# 테스트 데이터로 평가하기 --- (※6)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e336488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
